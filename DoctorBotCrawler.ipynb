{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d73bbe2e-deb4-4159-9ea7-873491185260",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install requests\n",
    "!pip install beautifulsoup4\n",
    "!pip install asyncio\n",
    "!pip install pynamodb\n",
    "!pip install cloudscraper\n",
    "!pip install unicodedata2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "id": "b73e5413-f5bc-4394-a4f2-84d667e9dff7",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def unique(list1):\n",
    "    unique_list = []\n",
    " \n",
    "    for x in list1:\n",
    "        # check if exists in unique_list or not\n",
    "        if x not in unique_list:\n",
    "            unique_list.append(x)\n",
    "    # print list\n",
    "    return unique_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd3757e7-2ed4-43a7-8c53-23dc0add33a5",
   "metadata": {},
   "source": [
    "### DynamoDB model for saving urls to a database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "id": "3164ad61-6cf1-414f-8cc1-9cba436b8f3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pynamodb.models import Model, DoesNotExist\n",
    "from pynamodb.attributes import ( UnicodeAttribute, UTCDateTimeAttribute )\n",
    "import datetime\n",
    "import os\n",
    "os.environ['AWS_ACCESS_KEY_ID'] = \"xyz\"\n",
    "os.environ['AWS_SECRET_ACCESS_KEY'] = \"abc\"\n",
    "\n",
    "class Page(Model):\n",
    "    class Meta:\n",
    "        region = 'us-west-2'\n",
    "        table_name = 'Pages'\n",
    "    website = UnicodeAttribute(hash_key=True)\n",
    "    url = UnicodeAttribute(range_key=True)\n",
    "    subject = UnicodeAttribute(null=True)\n",
    "    title = UnicodeAttribute(null=True)\n",
    "    text = UnicodeAttribute(null=True)\n",
    "    updatedAt = UTCDateTimeAttribute(default=datetime.datetime.now())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "id": "bc90fb6a-0bb7-43b9-aa41-282cd42a088e",
   "metadata": {},
   "outputs": [],
   "source": [
    "Page.create_table(read_capacity_units=1, write_capacity_units=1, wait=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07cb7900-70bb-4663-9865-e956a58b03bf",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Extract links from WebMD's directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 458,
   "id": "c7ab1c78-bb9f-4495-86af-dfe1fc0b3742",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cloudscraper\n",
    "import unicodedata2\n",
    "from bs4 import BeautifulSoup\n",
    "import asyncio\n",
    "from IPython.display import Markdown, display\n",
    "scraper = cloudscraper.create_scraper(delay=10, browser='chrome')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "id": "5a500a80-108c-481e-9e63-a270a555cf0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def scrapeLinks(letter):\n",
    "    html = scraper.get(f'https://www.webmd.com/a-to-z-guides/health-topics?pg={letter}')\n",
    "    html.encoding = 'utf-8'\n",
    "    soup = BeautifulSoup(html.text, \"html.parser\")\n",
    "    for tag in soup([\"script\", \"style\", \"noscript\", \"head\", \"meta\", \"img\", \"aside\", \"header\", \"footer\", \"nav\"]): # remove all javascript and stylesheet code\n",
    "        tag.extract()\n",
    "    for link in soup.findAll(\"a\", {\"data-metrics-link\" : True}):\n",
    "        link.decompose()\n",
    "    urls = []\n",
    "    for link in soup.find_all('a', href=True):\n",
    "        urls.append(link['href'])\n",
    "    return await unique(urls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f13bb60-2b01-48c6-b629-14b37c4ccb43",
   "metadata": {},
   "outputs": [],
   "source": [
    "letters = [\"a\", \"b\", \"c\", \"d\", \"e\", \"f\", \"g\", \"h\", \"i\", \"j\", \"k\", \"l\", \"m\", \"n\", \"o\", \"p\", \"q\", \"r\", \"s\", \"t\", \"u\", \"v\", \"w\", \"x\", \"y\", \"z\"]\n",
    "allLinks = []\n",
    "for letter in letters:\n",
    "    print(letter)\n",
    "    allLinks = allLinks + await scrapeLinks(letter)\n",
    "allLinks = await unique(allLinks)\n",
    "for link in allLinks:\n",
    "    await createPage(link)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df34a455-92c2-48ed-bd7d-33f9540c4b1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "allLinks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c22fd331-66a4-4253-9500-b1d0537e9d6a",
   "metadata": {},
   "source": [
    "### Function to scrape basic content pages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 459,
   "id": "79cb24d0-881e-4504-b554-c8aea47c9336",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def scrapeLink(url):\n",
    "    if Page.get('webmd', url).text is None:\n",
    "        html = scraper.get(url)\n",
    "        html.encoding = 'utf-8'\n",
    "        soup = BeautifulSoup(html.text, \"html.parser\")\n",
    "        for tag in soup([\"script\", \"style\", \"noscript\", \"head\", \"meta\", \"img\"]):\n",
    "            tag.extract()\n",
    "        article = soup.find(\"article\")\n",
    "        if article is not None:\n",
    "            articleLinksContainer = article.find(\"aside\")\n",
    "            urls = []\n",
    "            if articleLinksContainer is not None:\n",
    "                for link in articleLinksContainer.find_all('a', href=True):\n",
    "                    try:\n",
    "                        Page.get('webmd', url)\n",
    "                    except DoesNotExist:\n",
    "                        page = Page('webmd', link, subject='health')\n",
    "                        page.save()\n",
    "                        continue\n",
    "\n",
    "            text = ''\n",
    "            articleBody = article.find(\"div\", {\"class\": \"article__body\"})\n",
    "            if articleBody is None:\n",
    "                articleBody = article.find(\"div\", {\"class\": \"article-body\"})\n",
    "            if articleBody is not None:\n",
    "                for e in articleBody.descendants:\n",
    "                    if isinstance(e, str):\n",
    "                        text += e\n",
    "                    elif e.name in ['br', 'p', 'h1', 'h2', 'h3', 'h4','tr', 'th']:\n",
    "                        text += '\\n\\n'\n",
    "                    elif e.name == 'li':\n",
    "                        text += '\\n- '\n",
    "                text = unicodedata2.normalize(\"NFKD\",text)\n",
    "                page = Page.get('webmd', url)\n",
    "                page.update(actions=[Page.text.set(text)])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cec91de-d5a1-41af-8e80-50a0e016d908",
   "metadata": {},
   "source": [
    "### Function to scrape content from slideshow content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 420,
   "id": "1546f85a-ef40-41c7-8ef6-37e0ae2a40a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def scrapeSlides(url):\n",
    "    if Page.get('webmd', url).text is None:\n",
    "        html = scraper.get(url)\n",
    "        html.encoding = 'utf-8'\n",
    "        soup = BeautifulSoup(html.text, \"html.parser\")\n",
    "        for tag in soup([\"script\", \"style\", \"noscript\", \"head\", \"meta\", \"img\", \"picture\"]):\n",
    "            tag.extract()\n",
    "        for slideCount in soup.find_all(\"div\", {\"class\": \"slide-count-bbl\"}):\n",
    "            slideCount.extract()\n",
    "        slides = soup.find_all(\"div\", {\"class\": \"slide\"})\n",
    "\n",
    "        text = ''\n",
    "        for slide in slides:\n",
    "            for e in slide.descendants:\n",
    "                if isinstance(e, str):\n",
    "                    text += e.strip()\n",
    "                elif e.name in ['br', 'p', 'h1', 'h2', 'h3', 'h4','tr', 'th']:\n",
    "                    text += '\\n\\n'\n",
    "                elif e.name == 'li':\n",
    "                    text += '\\n- '\n",
    "        text = unicodedata2.normalize(\"NFKD\",text.strip())\n",
    "        page = Page.get('webmd', url)\n",
    "        page.update(actions=[Page.text.set(text)])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f5a7822-d6ed-4b2f-ac71-0fd6e986a197",
   "metadata": {},
   "source": [
    "### Function to scrape links from resource centers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 451,
   "id": "8d55b84a-a93c-4d2b-bedc-3318ffe49a83",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def scrapeResource(url):\n",
    "    print(url)\n",
    "    html = scraper.get(url)\n",
    "    html.encoding = 'utf-8'\n",
    "    soup = BeautifulSoup(html.text, \"html.parser\")\n",
    "    for tag in soup([\"script\", \"style\", \"noscript\", \"head\", \"meta\", \"img\"]):\n",
    "        tag.extract()\n",
    "        \n",
    "    linksContainer = soup.find(\"div\", {\"id\": \"key-links\"})\n",
    "    if linksContainer == None:\n",
    "        linksContainer = soup.find(\"section\", {\"id\": \"cncr-cncrtab\"})\n",
    "    if linksContainer is not None:\n",
    "        for link in linksContainer.find_all('a', href=True):\n",
    "            try:\n",
    "                Page.get('webmd', link['href'])\n",
    "            except DoesNotExist:\n",
    "                page = Page('webmd', link['href'], subject='health')\n",
    "                page.save()\n",
    "                continue"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "703391da",
   "metadata": {},
   "source": [
    "### Query links saved in DynamoDB and scrape their content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 461,
   "id": "b948000c-29cd-416c-b164-5112d0b8dfb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "allLinks = []\n",
    "for item in Page.query('webmd'):\n",
    "    allLinks.append(item.url)\n",
    "newLinks = []\n",
    "slideLinks = []\n",
    "normalLinks = []\n",
    "for link in allLinks:\n",
    "    if '.htm' in link:\n",
    "        newLinks.append(link)\n",
    "    elif 'slideshow' in link:\n",
    "        slideLinks.append(link)\n",
    "    else:\n",
    "        normalLinks.append(link)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ac93fa1-0cca-42f5-9cb2-9726b8d4a7d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Re run the above cell after scraping additional links from resource centers\n",
    "for link in newLinks:\n",
    "    await scrapeResource(link)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 460,
   "id": "95d84d74-0ac2-4ecb-a786-47c8649fa538",
   "metadata": {},
   "outputs": [],
   "source": [
    "for link in normalLinks:\n",
    "    await scrapeLink(link)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 430,
   "id": "1295a41e-4b70-4821-8353-c21698fe5362",
   "metadata": {},
   "outputs": [],
   "source": [
    "for link in slideLinks:\n",
    "    await scrapeSlides(link)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50b2e52f-1e8d-4510-b11b-e673a62380c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "notWorkingLinks = [\"https://www.webmd.com/parenting/baby/default.htm\", 'https://www.webmd.com/connect-to-care/addiction-treatment-recovery/default.htm', \"https://www.webmd.com/healthy-aging/default.htm\", \"https://www.webmd.com/beauty/default.htm\", \"https://www.webmd.com/breast-cancer/default.htm\", \"https://www.webmd.com/cancer/default.htm\", 'https://www.webmd.com/breast-cancer/default.htm']\n",
    "for link in newLinks:\n",
    "    if link in notWorkingLinks:\n",
    "        continue\n",
    "    else:\n",
    "        await scrapeResource(link)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 464,
   "id": "69c21612-bca6-44c0-abf4-4104133eef75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write to a text file that can be used in Faiss Index or other query methods\n",
    "texts = []\n",
    "for item in Page.query('webmd'):\n",
    "    if item.text:\n",
    "        texts.append(item.text.strip())\n",
    "text = \"\\n\\n\".join(texts)\n",
    "with open(r\"webmd.txt\", 'w') as fp:\n",
    "    fp.write(text.strip())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
